{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994b33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "# Show the figures / plots inside the notebook\n",
    "%matplotlib inline\n",
    "from skimage.color import rgb2gray,rgb2hsv, rgba2rgb\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "from commonfunctions import *\n",
    "from skimage import io, color, morphology\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.draw import polygon\n",
    "from skimage import transform\n",
    "from skimage.morphology import binary_closing\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "\n",
    "from skimage.exposure import histogram\n",
    "from matplotlib.pyplot import bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491a7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\downloadsd\\anaconda\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\downloadsd\\anaconda\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbadf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c23eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 Microcalcification cases\n",
      "\n",
      "Image        | Acc%     | Sens%    | Spec%    | Status\n",
      "------------------------------------------------------------\n",
      "mdb240       |  40.68 | 100.00 |  39.15 | ✓\n",
      "mdb231       |  52.44 |  40.97 |  53.61 | ✗\n",
      "mdb239       |  14.70 | 100.00 |   7.61 | ✓\n",
      "mdb223       |  20.48 | 100.00 |  20.35 | ✓\n",
      "mdb256       |  73.74 |  61.84 |  74.57 | ✓\n",
      "mdb249       |  26.79 | 100.00 |  17.74 | ✓\n",
      "mdb219       |  44.81 |  98.25 |  42.58 | ✓\n",
      "mdb211       |  16.04 | 100.00 |  15.36 | ✓\n",
      "mdb214       |  74.53 |   0.00 |  74.96 | ✗\n",
      "mdb238       |  26.97 | 100.00 |  25.95 | ✓\n",
      "mdb239       |  38.52 | 100.00 |  36.62 | ✓\n",
      "mdb241       |  46.27 |  70.62 |  44.47 | ✓\n",
      "mdb252       |  89.38 |   0.00 |  91.69 | ✗\n",
      "mdb253       |  12.75 | 100.00 |   9.35 | ✓\n",
      "mdb249       |  43.83 |  86.03 |  33.54 | ✓\n",
      "mdb226       |  38.12 | 100.00 |  37.98 | ✓\n",
      "mdb248       |  55.67 | 100.00 |  55.46 | ✓\n",
      "mdb218       |  23.68 | 100.00 |  23.45 | ✓\n",
      "mdb226       |  24.48 | 100.00 |  22.15 | ✓\n",
      "mdb222       |  46.47 |  71.92 |  46.11 | ✓\n",
      "mdb209       |  29.99 |  34.67 |  27.33 | ✗\n",
      "mdb223       |  26.29 | 100.00 |  23.21 | ✓\n",
      "\n",
      "============================================================\n",
      "SUMMARY (22 images processed):\n",
      "Average Accuracy:    39.39%\n",
      "Average Sensitivity: 80.20%\n",
      "Average Specificity: 37.42%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --------------------- Utilities ---------------------\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return img\n",
    "\n",
    "def image_crop(img, center_x, center_y, size=256):\n",
    "    half = size // 2\n",
    "    x1 = center_x - half\n",
    "    x2 = center_x + half\n",
    "    y1 = center_y - half\n",
    "    y2 = center_y + half\n",
    "    \n",
    "    img_h, img_w = img.shape\n",
    "    pad_top = abs(y1) if y1 < 0 else 0\n",
    "    pad_bottom = (y2 - img_h) if y2 > img_h else 0\n",
    "    pad_left = abs(x1) if x1 < 0 else 0\n",
    "    pad_right = (x2 - img_w) if x2 > img_w else 0\n",
    "    \n",
    "    crop_y1 = max(0, y1)\n",
    "    crop_y2 = min(img_h, y2)\n",
    "    crop_x1 = max(0, x1)\n",
    "    crop_x2 = min(img_w, x2)\n",
    "    \n",
    "    cropped = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "    \n",
    "    if pad_top > 0 or pad_bottom > 0 or pad_left > 0 or pad_right > 0:\n",
    "        cropped = cv2.copyMakeBorder(cropped, pad_top, pad_bottom, \n",
    "                                    pad_left, pad_right, \n",
    "                                    cv2.BORDER_CONSTANT, value=0)\n",
    "    return cropped\n",
    "\n",
    "# --------------------- Preprocessing (Paper Method) ---------------------\n",
    "def tophat_transform(img, se_size=3):\n",
    "    \"\"\"Top-Hat transform as described in paper\"\"\"\n",
    "    se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (se_size, se_size))\n",
    "    # Opening operation\n",
    "    opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, se)\n",
    "    # Top-Hat = Original - Opening\n",
    "    tophat = cv2.subtract(img, opened)\n",
    "    return tophat\n",
    "\n",
    "def extract_window_features(img, window_size=5):\n",
    "    \"\"\"Extract mean and std features using 5x5 window (paper method)\"\"\"\n",
    "    kernel = np.ones((window_size, window_size), np.float32) / (window_size * window_size)\n",
    "    \n",
    "    # Mean\n",
    "    mean_img = cv2.filter2D(img.astype(np.float32), -1, kernel)\n",
    "    \n",
    "    # Standard deviation\n",
    "    sqr_img = (img.astype(np.float32)) ** 2\n",
    "    mean_sqr = cv2.filter2D(sqr_img, -1, kernel)\n",
    "    std_img = np.sqrt(np.maximum(mean_sqr - mean_img**2, 0))\n",
    "    \n",
    "    return mean_img, std_img\n",
    "\n",
    "# --------------------- Feature Vector Construction (Paper Method) ---------------------\n",
    "def build_feature_vectors(original, enhanced, mean, std):\n",
    "    \"\"\"Build 4-dimensional feature vectors as in paper\"\"\"\n",
    "    h, w = original.shape\n",
    "    n_pixels = h * w\n",
    "    \n",
    "    FV = np.zeros((n_pixels, 4), dtype=np.float32)\n",
    "    FV[:, 0] = original.flatten()\n",
    "    FV[:, 1] = enhanced.flatten()\n",
    "    FV[:, 2] = mean.flatten()\n",
    "    FV[:, 3] = std.flatten()\n",
    "    \n",
    "    return FV\n",
    "\n",
    "# --------------------- Clustering (Paper Method) ---------------------\n",
    "def segment_with_kmeans(FV, n_clusters=2):\n",
    "    \"\"\"K-means segmentation as described in paper\"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='random', \n",
    "                   max_iter=100, n_init=10, random_state=42)\n",
    "    labels = kmeans.fit_predict(FV)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    return labels, centers\n",
    "\n",
    "def identify_mc_cluster(labels, centers, FV, enhanced_flat):\n",
    "    \"\"\"\n",
    "    Identify MC cluster using paper's criteria:\n",
    "    - Minimum number of data with maximum gray level\n",
    "    - Cluster separability\n",
    "    \"\"\"\n",
    "    n_clusters = len(centers)\n",
    "    cluster_scores = []\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        cluster_mask = (labels == i)\n",
    "        cluster_size = np.sum(cluster_mask)\n",
    "        \n",
    "        # Mean intensity of cluster in enhanced image\n",
    "        cluster_intensity = np.mean(enhanced_flat[cluster_mask])\n",
    "        \n",
    "        # Prefer smaller clusters with higher intensity (MCs are bright spots)\n",
    "        # Score favors high intensity and penalizes large size\n",
    "        score = cluster_intensity / (np.log(cluster_size + 2))\n",
    "        cluster_scores.append((i, score, cluster_size, cluster_intensity))\n",
    "    \n",
    "    # Select cluster with highest score\n",
    "    cluster_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    mc_cluster_id = cluster_scores[0][0]\n",
    "    \n",
    "    return mc_cluster_id\n",
    "\n",
    "# --------------------- Ground Truth Generation ---------------------\n",
    "def create_ground_truth_mask(shape, center_x, center_y, radius):\n",
    "    \"\"\"Create circular ground truth mask\"\"\"\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    h, w = shape\n",
    "    \n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_sq = (X - center_x)**2 + (Y - center_y)**2\n",
    "    mask[dist_sq <= radius**2] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# --------------------- Evaluation (Paper Method) ---------------------\n",
    "def evaluate_pixel_classification(pred_labels, gt_mask, mc_cluster_id, shape):\n",
    "    \"\"\"\n",
    "    Evaluate as in paper: pixel-level classification\n",
    "    - Sensitivity: TP / (TP + FN) \n",
    "    - Specificity: TN / (TN + FP)\n",
    "    - Accuracy: (TP + TN) / Total\n",
    "    \"\"\"\n",
    "    pred_mask = (pred_labels == mc_cluster_id).astype(np.uint8).reshape(shape)\n",
    "    gt_flat = gt_mask.flatten()\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    \n",
    "    TP = np.sum((pred_flat == 1) & (gt_flat == 1))\n",
    "    TN = np.sum((pred_flat == 0) & (gt_flat == 0))\n",
    "    FP = np.sum((pred_flat == 1) & (gt_flat == 0))\n",
    "    FN = np.sum((pred_flat == 0) & (gt_flat == 1))\n",
    "    \n",
    "    total = TP + TN + FP + FN\n",
    "    \n",
    "    sensitivity = TP / (TP + FN + 1e-10) * 100\n",
    "    specificity = TN / (TN + FP + 1e-10) * 100\n",
    "    accuracy = (TP + TN) / (total + 1e-10) * 100\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN\n",
    "    }\n",
    "\n",
    "# --------------------- Main Processing Pipeline ---------------------\n",
    "def process_roi_paper_method(roi, gt_center_x, gt_center_y, gt_radius):\n",
    "    \"\"\"\n",
    "    Complete processing pipeline following paper's methodology\n",
    "    \"\"\"\n",
    "    # Step 1: Top-Hat Enhancement\n",
    "    enhanced = tophat_transform(roi, se_size=3)\n",
    "    \n",
    "    # Step 2: Window-based feature extraction\n",
    "    mean_img, std_img = extract_window_features(enhanced, window_size=5)\n",
    "    \n",
    "    # Step 3: Build feature vectors\n",
    "    FV = build_feature_vectors(roi, enhanced, mean_img, std_img)\n",
    "    \n",
    "    # Step 4: K-means clustering\n",
    "    labels, centers = segment_with_kmeans(FV, n_clusters=2)\n",
    "    \n",
    "    # Step 5: Identify MC cluster\n",
    "    mc_cluster_id = identify_mc_cluster(labels, centers, FV, enhanced.flatten())\n",
    "    \n",
    "    # Step 6: Create ground truth\n",
    "    gt_mask = create_ground_truth_mask(roi.shape, gt_center_x, gt_center_y, gt_radius)\n",
    "    \n",
    "    # Step 7: Evaluate\n",
    "    metrics = evaluate_pixel_classification(labels, gt_mask, mc_cluster_id, roi.shape)\n",
    "    \n",
    "    # For visualization\n",
    "    pred_mask = (labels == mc_cluster_id).astype(np.uint8).reshape(roi.shape)\n",
    "    \n",
    "    return enhanced, pred_mask, gt_mask, metrics\n",
    "\n",
    "# --------------------- Batch Processing ---------------------\n",
    "def process_dataset(csv_path, visualize_first=True):\n",
    "    \"\"\"Process entire dataset\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Filter for CALC cases with valid coordinates\n",
    "    calc_cases = df[(df['CLASS'] == 'CALC') & (df['X'].notna())].copy()\n",
    "    print(f\"Found {len(calc_cases)} Microcalcification cases\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"{'Image':<12} | {'Acc%':<8} | {'Sens%':<8} | {'Spec%':<8} | Status\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for idx, (index, row) in enumerate(calc_cases.iterrows()):\n",
    "        ref_num = row['REF']\n",
    "        image_path = row['PATH']\n",
    "        \n",
    "        try:\n",
    "            raw_x = int(row['X'])\n",
    "            raw_y = int(row['Y'])\n",
    "            radius = int(row['RADIUS'])\n",
    "        except (ValueError, KeyError):\n",
    "            print(f\"{ref_num:<12} | SKIP: Invalid data\")\n",
    "            continue\n",
    "        \n",
    "        # Handle Y-flip for MIAS\n",
    "        center_y = 1024 - raw_y\n",
    "        center_x = raw_x\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"{ref_num:<12} | ERROR: File not found\")\n",
    "            continue\n",
    "            \n",
    "            # Load and crop\n",
    "        img = load_image(image_path)\n",
    "        roi = image_crop(img, center_x, center_y, size=256)\n",
    "            \n",
    "            # ROI center is always at 128, 128\n",
    "        roi_center = 128\n",
    "            \n",
    "            # Process using paper method\n",
    "        enhanced, pred_mask, gt_mask, metrics = process_roi_paper_method(\n",
    "            roi, roi_center, roi_center, radius\n",
    "        )\n",
    "            \n",
    "        results.append({\n",
    "            'ref': ref_num,\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'sensitivity': metrics['sensitivity'],\n",
    "            'specificity': metrics['specificity']\n",
    "        })\n",
    "            \n",
    "        status = \"✓\" if metrics['sensitivity'] > 50 else \"✗\"\n",
    "        print(f\"{ref_num:<12} | {metrics['accuracy']:>6.2f} | \"\n",
    "                f\"{metrics['sensitivity']:>6.2f} | {metrics['specificity']:>6.2f} | {status}\")\n",
    "            \n",
    "           \n",
    "            \n",
    "        \n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if results:\n",
    "        avg_acc = np.mean([r['accuracy'] for r in results])\n",
    "        avg_sens = np.mean([r['sensitivity'] for r in results])\n",
    "        avg_spec = np.mean([r['specificity'] for r in results])\n",
    "        \n",
    "        print(f\"SUMMARY ({len(results)} images processed):\")\n",
    "        print(f\"Average Accuracy:    {avg_acc:.2f}%\")\n",
    "        print(f\"Average Sensitivity: {avg_sens:.2f}%\")\n",
    "        print(f\"Average Specificity: {avg_spec:.2f}%\")\n",
    "    else:\n",
    "        print(\"No images processed successfully\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --------------------- Run ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    CSV_PATH = \"train_dataset.csv\"\n",
    "    results = process_dataset(CSV_PATH, visualize_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1e7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mc_data(roi):\n",
    "    \"\"\"\n",
    "    Lightweight getter for MC extraction.\n",
    "    Uses existing functions and keeps logic minimal.\n",
    "    \"\"\"\n",
    "\n",
    "    if roi is None or roi.size == 0:\n",
    "        return [], None\n",
    "\n",
    "    # 1. Use existing enhancement\n",
    "    tophat_norm = tophat_transform(roi)\n",
    "\n",
    "    # 2. Simple binary map for MC candidates\n",
    "    _, bw = cv2.threshold(\n",
    "        tophat_norm,\n",
    "        0, 255,\n",
    "        cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # 3. Find contours (no extra processing)\n",
    "    contours, _ = cv2.findContours(\n",
    "        bw,\n",
    "        cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    return contours, tophat_norm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
